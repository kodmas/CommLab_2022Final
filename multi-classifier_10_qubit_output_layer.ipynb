{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import qiskit\n",
    "from qiskit import transpile, assemble\n",
    "from qiskit.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2000, 0.8000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.Tensor([0.2]), 1 - torch.Tensor([0.2])), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2000, 0.8000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.Tensor([[0.2]]), 1 - torch.Tensor([[0.2]])), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    \"\"\" \n",
    "    This class provides a simple interface for interaction \n",
    "    with the quantum circuit \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.n_qubits = n_qubits\n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        \n",
    "        self._circuit.h(all_qubits)\n",
    "        self._circuit.barrier()\n",
    "        \n",
    "        self.theta = []\n",
    "        for i in range(n_qubits):\n",
    "            self.theta.append(qiskit.circuit.Parameter('theta' + str(i)))\n",
    "            self._circuit.ry(self.theta[-1], i)\n",
    "        \n",
    "        self._circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "\n",
    "    def run(self, thetas):\n",
    "        #print('in the run')\n",
    "        #print('theta = ', thetas)\n",
    "        t_qc = transpile(self._circuit,\n",
    "                         self.backend)\n",
    "        dict_for_use = {}\n",
    "        for i in range(len(self.theta)):\n",
    "            dict_for_use[self.theta[i]] = thetas[i]\n",
    "        qobj = assemble(t_qc,\n",
    "                        shots=self.shots,\n",
    "                        parameter_binds = [dict_for_use])\n",
    "        \n",
    "        job = self.backend.run(qobj)\n",
    "        result = job.result().get_counts()\n",
    "        \n",
    "        #print(result)\n",
    "        collection = [0] * self.n_qubits\n",
    "        #It means the probability of '1' for each qubit\n",
    "        for str_ in list(result.keys()):\n",
    "            for j in range(len(str_)):\n",
    "                if int(str_[len(str_) - 1 - j]):\n",
    "                    collection[j] += 1/self.shots * result[str_]\n",
    "        \n",
    "        #print('collection = ', collection)\n",
    "        \n",
    "        return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(int('0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1, 2, 3])\n",
    "np.sum(np.array(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌────────────┐ ░ ┌─┐      \n",
       "   q_0: ┤ H ├─░─┤ Ry(theta0) ├─░─┤M├──────\n",
       "        ├───┤ ░ ├────────────┤ ░ └╥┘┌─┐   \n",
       "   q_1: ┤ H ├─░─┤ Ry(theta1) ├─░──╫─┤M├───\n",
       "        ├───┤ ░ ├────────────┤ ░  ║ └╥┘┌─┐\n",
       "   q_2: ┤ H ├─░─┤ Ry(theta2) ├─░──╫──╫─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ║  ║ └╥┘\n",
       "meas: 3/══════════════════════════╩══╩══╩═\n",
       "                                  0  1  2 </pre>"
      ],
      "text/plain": [
       "        ┌───┐ ░ ┌────────────┐ ░ ┌─┐      \n",
       "   q_0: ┤ H ├─░─┤ Ry(theta0) ├─░─┤M├──────\n",
       "        ├───┤ ░ ├────────────┤ ░ └╥┘┌─┐   \n",
       "   q_1: ┤ H ├─░─┤ Ry(theta1) ├─░──╫─┤M├───\n",
       "        ├───┤ ░ ├────────────┤ ░  ║ └╥┘┌─┐\n",
       "   q_2: ┤ H ├─░─┤ Ry(theta2) ├─░──╫──╫─┤M├\n",
       "        └───┘ ░ └────────────┘ ░  ║  ║ └╥┘\n",
       "meas: 3/══════════════════════════╩══╩══╩═\n",
       "                                  0  1  2 "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator = qiskit.Aer.get_backend('aer_simulator')\n",
    "\n",
    "circuit = QuantumCircuit(3, simulator, 1000)\n",
    "#print('Expected value for rotation pi {}'.format(circuit.run([np.pi])[0]))\n",
    "circuit._circuit.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100': 101, '111': 120, '110': 126, '000': 120, '101': 128, '011': 130, '010': 130, '001': 145}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.523, 0.506, 0.475]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit.run([0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridFunction(Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "        \n",
    "        print('input[0].tolist() = ', input[0].tolist())\n",
    "        print('input.shape= ', input.shape)\n",
    "        expectation_z = ctx.quantum_circuit.run(input[0].tolist())\n",
    "        #print(expectation_z)\n",
    "        #here\n",
    "        result = torch.tensor([expectation_z])\n",
    "        ctx.save_for_backward(input, result)\n",
    "\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\" Backward pass computation \"\"\"\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        \n",
    "        \n",
    "        input_list = np.array(input.tolist())\n",
    "        #print('input_list =', input_list)\n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "        \n",
    "        #print('shift_right =', shift_right)\n",
    "        #print('shift_left =', shift_left)\n",
    "        #gradients = []\n",
    "        #print('grad_output.float() = ', grad_output.float())\n",
    "        \n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "            expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
    "            \n",
    "            gradient = 0.5 * (torch.tensor([expectation_right]) - torch.tensor([expectation_left]))\n",
    "            #print('gradient = ', gradient)\n",
    "            gradients = gradient.numpy()\n",
    "            #gradients.append(gradient)\n",
    "        #print('gradients = ', gradients)\n",
    "            \n",
    "        #gradients = np.array([gradients]).T\n",
    "        #print('grad_output', grad_output.float())\n",
    "        #print('gradients', torch.tensor(gradients).float())\n",
    "        #print('multiply', torch.tensor(gradients).float() * grad_output.float())\n",
    "        return torch.tensor(gradients).float() * grad_output.float(), None, None\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self, num, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(num, backend, shots)\n",
    "        self.shift = shift\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.495],\n",
       "       [0.2  ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[0.4950, 0.2]]).numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.495]]],\n",
       "\n",
       "\n",
       "       [[[0.2  ]]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[torch.Tensor([[0.4950, 0.2]]).numpy() ]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.495]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[torch.Tensor([[0.4950]])]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 3., 2., 4., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 4], dtype=int64),)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.Tensor([5, 3, 2, 4, 1]))\n",
    "np.where(torch.Tensor([5, 3, 2, 4, 1]) <= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "35.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Concentrating on the first 100 samples\n",
    "n_samples = 100\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "for i in range(2, 10):\n",
    "    idx = np.append(idx, np.where(X_train.targets == i)[0][:n_samples])\n",
    "    \n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx8AAACdCAYAAADVNMXrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAd20lEQVR4nO3deXRU5RnH8SeEbISAEDAQ9kBEoCwaRFQoVNAgYROVglJRFCpU6aFVObVEiGxFtoqoQFFQXABZPAqIa6QqGFGoFClrEAigAiIgYCDJ2z84jvO8SSaZMHNnJvl+zuGc+5u5d+aFeXIzL/c+94YZY4wAAAAAgJ9VCvQAAAAAAFQMTD4AAAAAOILJBwAAAABHMPkAAAAA4AgmHwAAAAAcweQDAAAAgCOYfAAAAABwBJMPAAAAAI5g8gEAAADAESE9+fjmm28kLCxMpk+f7rPX/OijjyQsLEw++ugjn73m+PHjJSwszGevh+JRE3BHPcBGTcBGTcBGTfiX45OPRYsWSVhYmHzxxRdOv3XIunDhgmRkZEhSUpJERUVJUlKSTJw4UfLy8gI9NJ+gJrzzy06xuD/Dhg0L9BAvCfXgnfJeDyLURFmdP39eJk+eLFdeeaVER0dLQkKCpKWlSU5OTqCHdsmoCe+wn0BRAvX9srJfXx0+MXjwYHn99ddl6NCh0r59e/nss88kPT1dDhw4IPPnzw/08OCw2rVry+LFiws9vm7dOnnllVfk5ptvDsCoECjUA4py4cIFSUtLkw0bNsiwYcOkTZs2cuLECcnKypKTJ09K/fr1Az1EOIj9BIoSqO+XTD6C3KZNm2TZsmWSnp4uTzzxhIiIPPDAA1KrVi2ZOXOmPPjgg9KmTZsAjxJOio2NlcGDBxd6fNGiRVKtWjXp3bt3AEaFQKEeUJRZs2bJ+vXr5ZNPPpEOHToEejgIMPYTsAXy+2VQ9nycP39eHn/8cUlJSZHq1atLbGysdO7cWTIzM4vdZtasWdKoUSOJiYmRLl26yLZt2wqts2PHDrn99tulZs2aEh0dLe3bt5c333yzVGPKysqSHj16SPXq1aVKlSrSpUsX+fTTTwut98knn8g111wj0dHR0rRpU5k3b16Rr3fs2DHZsWOHnD171uP7fvzxxyIiMnDgQPX4wIEDxRgjS5cuLdX4Qx014dmRI0ckMzNT+vfvL9HR0V5vH2qoB88qWj2IUBPuCgoK5KmnnpJbb71VOnToIHl5eWWqo1BHTXjGfqJi10RAv18ahy1cuNCIiNm0aVOx6xw9etTUrVvX/OUvfzHPPfecefLJJ03z5s1NRESE2bJli2u9ffv2GRExrVu3No0bNzZTp041GRkZpmbNmqZ27drm22+/da27bds2U716ddOyZUszdepUM2fOHPPb3/7WhIWFmZUrV7rWy8zMNCJiMjMzXY998MEHJjIy0lx33XVmxowZZtasWaZNmzYmMjLSZGVludbbunWriYmJMQ0bNjRTpkwxEyZMMAkJCaZNmzbG/qceN25cofcpyuTJk42ImOzsbPX4119/bUTEpKametw+FFATF5W2Jooyc+ZMIyLmvffe83rbYEM9XEQ9/IqauKi0NfHf//7XiIiZOHGiGTZsmImMjHT9nT/88MMS/rVDAzVxEfuJX1ETF4XC98ugnHzk5eWZ3Nxc9diJEydMQkKCGTp0qOuxX4ojJibG5OTkuB7PysoyImJGjx7teqxbt26mdevW5ueff3Y9VlBQYK6//nqTnJzseswujoKCApOcnGxSU1NNQUGBa72zZ8+aJk2amJtuusn1WL9+/Ux0dLTZv3+/67Ht27eb8PDwMhfHihUrjIiYxYsXq8fnzp1rRMT85je/8bh9KKAmLrqUXyIpKSmmbt26Jj8/3+ttgw31cBH18Ctq4qLS1sTKlSuNiJj4+HiTnJxsFi5caBYuXGiSk5NNZGSk+eqrrzxuHwqoiYvYT/yKmrgoFL5fBuXkw11+fr45fvy4OXr0qElLSzPt2rVzPfdLcQwaNKjQdtdee61p3ry5McaY48ePm7CwMDNhwgRz9OhR9ScjI8OIiKu47OLYvHmzERHz4osvFtr2/vvvN1FRUSY/P9/k5eWZmJgYM3DgwEJj6dmzZ6HiKK1z586ZRo0amYSEBLNixQrzzTffmKVLl5r4+HhTuXJl07Rp0zK9bjChJi7Nzp07C+0MQxn1cGnKWz0YQ01466WXXjIiYiIjI82BAwdcj+/fv99ERESYu+66q0yvG0yoiUvDfoKaCOT3y6BtOH/xxRdlxowZsmPHDrlw4YLr8SZNmhRaNzk5udBjV1xxhSxbtkxERPbs2SPGGElPT5f09PQi3+/777+XevXqFXp89+7dIiIyZMiQYsd68uRJyc3NlXPnzhU5lubNm8vatWuL3d6T6OhoWbNmjQwYMEBuu+02ERGJioqSJ598UiZNmiRVq1Yt0+uGImqiaK+88oqIiNx1110+eb1QQT0UraLWgwg18YuYmBgREbnhhhukQYMGrscbNmwonTp1kg0bNpTpdUMRNVE09hPURCC/Xwbl5OPll1+We+65R/r16yePPPKIXH755RIeHi5TpkyRvXv3ev16BQUFIiLy8MMPS2pqapHrNGvWzOO206ZNk3bt2hW5TtWqVSU3N9frcZVWq1atZNu2bbJ9+3Y5ceKEtGzZUmJiYmT06NHSpUsXv71vMKEmivfqq69K8+bNJSUlxZH3CwbUQ/EqYj2IUBPuEhMTRUQkISGh0HOXX365bNmyxS/vG2yoieKxn6AmRAL3/TIoJx/Lly+XpKQkWblypbpz47hx44pc/5fZo7tdu3ZJ48aNRUQkKSlJREQiIiKke/fuXo2ladOmIiJSrVo1j9vWrl1bYmJiihzLzp07vXrPooSFhUmrVq1cee3atVJQUOD13ydUURNFy8rKkj179rguk1dRUA9Fq6j1IEJNuGvdurVERETIoUOHCj13+PBhqV27dplfO5RQE0VjP0FNuAvE98ugvNRueHi4iIgYY1yPZWVlycaNG4tc/4033lA72c8//1yysrLklltuEZGL/9PTtWtXmTdvnhw5cqTQ9kePHi12LCkpKdK0aVOZPn26/PTTT8VuGx4eLqmpqfLGG2/IgQMHXM//73//k3feeafQdpdyebxz585Jenq61K1bVwYNGuT19qGImijaq6++KiIid955Z6m3KQ+oh6JV1HoQoSbcxcXFSc+ePWXDhg2yY8cO9bobNmyQm266yeP25QU1UTT2E9REcZz6fhmwIx8vvPCCrFu3rtDjf/7zn6VXr16ycuVKufXWWyUtLU327dsnc+fOlZYtWxb5ATVr1kw6deokI0aMkNzcXPnnP/8p8fHx8uijj7rWeeaZZ6RTp07SunVrGTZsmCQlJcl3330nGzdulJycHPnqq6+KHGelSpVkwYIFcsstt0irVq3k3nvvlXr16smhQ4ckMzNTqlWrJm+99ZaIiGRkZMi6deukc+fOMnLkSMnLy5Onn35aWrVqJVu3blWvO2fOHMnIyJDMzEzp2rWrx3+rAQMGSGJiorRs2VJOnTolL7zwgmRnZ8uaNWskLi6upH/qkEFNlL4mRETy8/Nl6dKl0rFjR9f/oJQn1AP1YKMmSl8TkydPlg8++EBuvPFGGTVqlIiIzJ49W2rWrCmPPfaYx21DCTXBfsJGTYTA90u/tbIX45erERT35+DBg6agoMBMnjzZNGrUyERFRZmrrrrKrF692gwZMsQ0atTI9Vq/XI1g2rRpZsaMGaZBgwYmKirKdO7cuchLCe7du9fcfffdpk6dOiYiIsLUq1fP9OrVyyxfvty1TlHXYTbGmC1btpj+/fub+Ph4ExUVZRo1amQGDBhgPvjgA7Xe+vXrTUpKiomMjDRJSUlm7ty5rsueufPm8nhTp041V155pYmOjjY1atQwffr0UdejDnXUxEXeXjJx3bp1RkTM7NmzS7V+qKAeLqIefkVNXORtTXz55Zeme/fuJjY21sTFxZm+ffuaXbt2lWrbYEdNXMR+4lfUxEWh8P0yzBi3Y08AAAAA4CdB2fMBAAAAoPxh8gEAAADAEUw+AAAAADiCyQcAAAAARzD5AAAAAOCIMt/no6CgQA4fPixxcXHqLpEIfsYYOX36tCQmJkqlSr6bf1IToclf9SBCTYQq9hGwUROwUROwlbYmyjz5OHz4sDRo0KCsmyMIHDx4UOrXr++z16MmQpuv60GEmgh17CNgoyZgoyZgK6kmyjxVLU931q6ofP0ZUhOhzR+fHzUR2thHwEZNwEZNwFbSZ1jmyQeHwkKfrz9DaiK0+ePzoyZCG/sI2KgJ2KgJ2Er6DGk4BwAAAOAIJh8AAAAAHMHkAwAAAIAjmHwAAAAAcASTDwAAAACOKPN9PgAAQNn17dtX5VWrVqk8adIkldPT0/0+JgDwN458AAAAAHAEkw8AAAAAjmDyAQAAAMAR9HwAAOCAjh07qjx+/HiP61epUsWPowGAwODIBwAAAABHMPkAAAAA4AgmHwAAAAAcQc8HAAB+EB0drfKECRNUbtu2rcpff/21x/UBoDzgyAcAAAAARzD5AAAAAOAIJh8AAAAAHEHPBwAAfjB8+HCVu3Xr5nF9+74fP/74o49HBACBx5EPAAAAAI5g8gEAAADAEUw+AAAAADiCng8AAHxg3LhxKv/973/3uH56errKK1eu9PmYACDYcOQDAAAAgCOYfAAAAABwBJMPAAAAAI6g58NNVFSUa3no0KHquWeffVblWbNmqXzkyBGVZ8+erXJubq4vhggvbdiwQeWOHTt6XP/ll19W2RhT6vcKCwtTefny5SpnZmaqfPr06VK/NoDgdPXVV7uWx44dq54LDw9XecWKFSpPmTJFZW/2N3BO5cr6q1JMTIzKDzzwgMqXXXZZsa/VtWtXla+77jqP771q1SqVd+zYoXJ2drbKixYtUjk/P9/j68M3qlevrnKPHj1Ufu2111zL9neFkydPqvyPf/zDYy4POPIBAAAAwBFMPgAAAAA4gskHAAAAAEdU6J6Pxo0bqzxmzBjX8vDhw9VzX3zxhcp270BycrLKTZo0UXn06NEq0wPijL1796p87bXXelx/8ODBKl9Kz8ddd92l8vHjx1V+5513VH7xxRdVfv/990v93uVJXFycyrGxsSrbPzuVKun/Qzl//rzKgeytsc8Nt88dt/9utWrVUvnuu+/2+PoTJkxQmT4i/6tatarKq1evdi3bn++ePXtUtu/7UVBQ4OPRwRdq1qypckZGhsojR44s82vbvydK+h3Tr18/r17fHvu0adO82h5Fs/u37O+Ijz32mMqJiYkqu3/O3377rXouPj5e5YkTJ6p87NgxlQ8dOqTyhx9+qHIofL/kyAcAAAAARzD5AAAAAOAIJh8AAAAAHFGhej569eql8vz581VOSEhwLc+dO1c9Z/ds2OeVL1u2TOU//vGPKk+ePFnlnJycUowYl8q9j0ek8Pmw9rW47XMx3bmf2y0ikpKSonLdunVVts8Nt8/rvPPOO1Xu06ePyqNGjVLZ7gkpr+x75PzhD39Q2b6njt1XYT+/ZcsWlUs6x9ru72rfvr3KZ8+edS3v379fPdeiRQuV7d6vGjVqqNyyZUuvxmbbvn27yvY1/nHp7Pr6+OOPVa5Tp45r+eDBg+q5W265RWW7BwTBoV27diq/+eabKterV0/lAwcOqOzpHPsZM2aonJeXp3JJP/MNGzZUedy4cR7Xt/c5KBu7/87u+7Hv7WKz9wUDBw50Ldu9qPbvfruXb968eR7fy/5uYN+nLhhx5AMAAACAI5h8AAAAAHAEkw8AAAAAjijXPR+DBg1S+ZlnnlH5sssuU9m9B6SkHg/7XgT2fT4QHA4fPqyy3Wdhf87jx4/32XtfccUVKt96660q231Adk3Z55xWFPa9Lexzou3eGpv9c+1tX4V9fxab+3X6ve3R8DW7Z4meD9/79NNPVW7btq3K+fn5ruVHH31UPUePR2iwz5G3ezzWrVunsr2P+PHHH/0yLpHCP+O2U6dOqfzUU0/5bSwVySOPPKJyST0e9r02+vfvr7KnezA9//zzKjdt2lRlu3fVZvczhwKOfAAAAABwBJMPAAAAAI5g8gEAAADAEeWq5+Pmm29W+ZVXXlH5p59+Utk+h8++74cngwcPVtk+D3j37t0e3xuBcfLkSZV92eNh27Vrl8r2+d/uvQNFZaAkZ86cCfQQyh37mvn2vt2+p8Pw4cNdy0uWLPHpWOz7wrjfi0qkcC9idna2T9+/ohg7dqzKa9euVTkrK0tlf/Z42PeVsXsPbHbN7dy50+djqgjq16+vckk9HnYN3HbbbSp76vGwRUVFqezeR1YamzZt8mr9YMCRDwAAAACOYPIBAAAAwBFMPgAAAAA4IqR7PuLj41VesGCByvY1+Pv27atyZmZmqd8rJSVFZfueIfZ7NWvWTOWqVauq7M9zRhEc7HN37WvD2zVj94hU1Hs2PPvssyqPGDEiQCMJfseOHQv0EEJeu3btVL799ttVtnux3n//fZUXL15c5ve270lj9xLef//9Krdp00Zlu+fDvpfQ22+/XeaxVST2vTLs+3r4k32+/9NPP61y165dVf7hhx9UnjNnjl/GVdEkJSWpHB0drXJBQYHK9u8lu4Y8sb8fTpw4UeU77rij1K8lIjJt2jSv1g8GHPkAAAAA4AgmHwAAAAAcweQDAAAAgCNCuudj6NChKterV0/lnJwclbdu3Vrq17bP55s5c6aXo0NFZ983xu45Onv2rMozZsxQ+fjx4/4ZWJB76KGHVLavud+qVSuV7Wuc2z+7Xbp0UdnutbF98cUXKrdv317lL7/80rVs94Lt379f5YYNG6pcp04dlStV0v//Y59XbPv5559V/uijjzyuj5INHDhQZbtXy66XSZMmlfm9rr/+epVvvPFGlTMyMlQu6d4/kZGRKg8ZMkRlej6C38MPP6zyvffe69X6X3/9tc/HVBFVq1ZN5cqV9ddj9/2+iMiyZcu8en3330N2n5j93fWbb75RuXHjxirbPcP79u3zaizBgCMfAAAAABzB5AMAAACAI0L6tCv7FAbbxo0bVbZPY7EvYdezZ0/Xsn3qx7Zt21TevHmzyvYlEe3Lpv70008ex4rQN2bMGJXtS3ba7NOs/vWvf/l8TOWBfepISaeSrF+/3p/D8SguLk7lzz//XOWEhASV7dOsSjolzD7VlNNqvFe9enWVU1NTPa7/5ptvqvzZZ5+V+r3sS9++9NJLKsfGxnrcPisrS2X790i3bt1UPnz4cKnHhsDo2LGjyn/96189rr9kyRKVX3/9dZ+PCSX797//7fF5+1K93bt3V3ns2LGuZfv3xPDhw1W2WwbsU4+XLl2qsn26byjgyAcAAAAARzD5AAAAAOAIJh8AAAAAHBHSPR/jx49XuUOHDioPGDDAYz516pTKO3fudC3bt7dfvXq1yvZl1+xLIs6ZM0dl+9JoCH12jUyZMsXj+nZN2PWL0HfdddepnJycfEmvt3LlSpXtc3/hvd/97ncqt23bVmW7D8fuzbK5X5LTvtRtSX1cubm5Ktvnidt9i4MGDVL53LlzKtuXYUXwee+991SuUqWKyvZlU++77z6V7cttwzd2796t8rFjx1S+5557VG7RooXK9r7f7i1z7xX7/e9/r56zezxGjx7tcaxPPvmkx+dDAUc+AAAAADiCyQcAAAAARzD5AAAAAOCIkO75OH36tMr9+vVT2T6317Z161aV7XtzuEtMTFT5qquuUtm9X0Sk8LW5Efrsa/ZPnTrV4/r2vWEmTJjg8zEhsGrUqKHyo48+ekmvd+LECZWfeOIJle19HkoWHh6u8oMPPuhx/aefflrlTz75xOP67udv2z0eeXl5Kts9HHaPx4ULF1S+/vrri30vEZE+ffp4HBsCb8WKFSrb93axf6YHDx6sMj0ezrC/w/Xu3Vvl2bNnq9yjRw+V7fv/LF++XOVFixa5lu39fLVq1VQeMWKEx7Ha/cqhiCMfAAAAABzB5AMAAACAI5h8AAAAAHBESPd82I4fP66yfc7dpVi1apXH5+3z/eyxIDS5X1d/wYIF6rno6GiVd+zYoXJaWprKR48e9fHoEGj9+/dXuWvXrl5tv379epXfeustle2+IXivSZMmKl9zzTUe11+4cKHK9j2c7D4N9/v32D0bI0eOVPndd99VuVevXirb1/ePi4tT2e41RHAaNWqUa9nuFbTracyYMSrb3yUQGJ9//rnKHTt29Nt71alTR+VmzZr57b2CBUc+AAAAADiCyQcAAAAARzD5AAAAAOCIctXz4Uv2ubj2ubZr1qxR2T63F6HJvp/Ls88+61q2ezyys7NV7tatm8pHjhzx8egQbOxr9tvnc5ekRYsWKt94442XPCZof/rTn1S2+yhs9jX3K1fWvybfeeedYrc9duyYykOGDFHZfX8iIhIREaGyMUZl+z4vCE61a9dW+aabbnIt25/p4sWLVZ47d67/BoaQZNdMecSRDwAAAACOYPIBAAAAwBFMPgAAAAA4gp4PN40bN3Ytz58/Xz1nn/drX4//3LlzfhsX/CclJUXlTZs2FbuufR8PejwqJvdrsD/00EPqOW/P1a0I5/YGmt3HVZIVK1aofOrUqVJvW6tWLZU7derkcf29e/eq/Pjjj6v82muvlfq94Ry7b8i+J0TDhg1dyz/88IN6zu4DAnr27Onx+f3796ucm5vrz+E4giMfAAAAABzB5AMAAACAI5h8AAAAAHAEPR9u7rvvPtdyQkKCes7uAbEzglNMTIzKAwcOVNm+7r7t0KFDxW5Lj0fFNHz4cNdykyZNvNrWPnd36NChPhkTfMe+Z4OdvWF/3oMHD1Z58+bNKtM7GJzse78sWrRIZfceDxGRo0ePupZ79Ojht3GhfIiPj/f4/Ntvv63ymTNn/DkcR3DkAwAAAIAjmHwAAAAAcASTDwAAAACOqNA9H3ZfxwMPPFDsuhMnTvT3cOADUVFRKt95550ql9SrY9/LIzU11bV88ODBSxwdKrrly5ervH79+gCNpOKw9+tnz55V2T6fPy0tTWX38/dFCt/Twf1eHfbnu23bNo/vjdBwww03qNy3b1+P60+fPt21/J///McfQ0I5UrNmTZXPnz+v8lNPPeXkcBzBkQ8AAAAAjmDyAQAAAMARTD4AAAAAOKJC93yMHDlSZffz7lavXq2e454OoeHee+9V+ZlnnvG4fnZ2tsrdunVTmc8dCG0nTpxQ2d5HACWx789iy8nJUfn555/353AQ4iIiIlTu06ePynl5eSrv2rXL72NyGkc+AAAAADiCyQcAAAAARzD5AAAAAOCICt3z0atXL5UvXLjgWs7IyFDP5efnOzImeOeOO+5Q+bnnnlPZGKPynDlzVB41apR/BoZyKywsrMhlAOXD1VdfrXLv3r09rj9o0CCV7T4jwF2nTp1UTkxMVLki3A+IIx8AAAAAHMHkAwAAAIAjmHwAAAAAcESF7vm46qqrVN64caNrefPmzU4PB6UwYsQIlWfOnKnyqVOnVJ4/f77Kf/vb3/wzMFQYPXr0cC3bPUUAQt/o0aNVjo2NVXnfvn0q79mzx+9jAsoTjnwAAAAAcASTDwAAAACOYPIBAAAAwBEVuufDtmTJkkAPASVo3769ypGRkSrb9/l45JFH/D4mVCzbt293Lbdo0cLjuu59ZCIir732ml/GBKDsateurXK7du08rj9kyBCVv//+e18PCSjXOPIBAAAAwBFMPgAAAAA4gskHAAAAAEdU6J6PNWvWqLxgwYIAjQSlVaNGDZWzs7NVnjZtmpPDQQW0atUq13KTJk3Uc2vXrlV56tSpKp87d85/AwNQJvXq1VO5ZcuWKr/77rsqf/bZZ34fE8qv7777TuUzZ86oHBYW5uRwAoIjHwAAAAAcweQDAAAAgCOYfAAAAABwRJgxxpRlw1OnTkn16tV9PR446OTJk1KtWjWfvR41Edp8XQ8i5b8mYmNjVbbP3Q117CNgoyZgoyZgK6kmOPIBAAAAwBFMPgAAAAA4osyX2i3j2VoIIr7+DKmJ0OaPz6+81wR/v8C+HpxHTcBGTcBW0mdY5iMfp0+fLuumCBK+/gypidDmj8+vvNfE2bNn1Z/yhn0EbNQEbNQEbCV9hmVuOC8oKJDDhw9LXFxchbghSnlijJHTp09LYmKiVKrkuzPvqInQ5K96EKEmQhX7CNioCdioCdhKWxNlnnwAAAAAgDdoOAcAAADgCCYfAAAAABzB5AMAAACAI5h8AAAAAHAEkw8AAAAAjmDyAQAAAMARTD4AAAAAOILJBwAAAABHMPkAAAAA4AgmHwAAAAAcweQDAAAAgCOYfAAAAABwxP8B53sRN9qNKM0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0].numpy().squeeze(), cmap='gray')\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets.item()))\n",
    "    \n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c9d8a24668>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[0, 0, 0]]).to(float)\n",
    "a = torch.Tensor(a).to(float)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "        self.hybrid = Hybrid(10, qiskit.Aer.get_backend('aer_simulator'), 1000, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        #x = x.view(1, -1)\n",
    "        x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #print('input = ', x)\n",
    "        x = self.hybrid(x)\n",
    "        #x = torch.Tensor(x).to(float)\n",
    "        #print(x)\n",
    "        x = F.softmax(x)\n",
    "        #print('x = ', x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input[0].tolist() =  [0.012883372604846954, 0.03751307725906372, 0.035095058381557465, 0.055988699197769165, 0.11940065026283264, -0.1586601883172989, 0.02501482143998146, 0.05290183424949646, -0.02261558547616005, -0.14386816322803497]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.045454636216163635, 0.04340609163045883, 0.06526491791009903, 0.08620420098304749, 0.07195208221673965, -0.17469507455825806, 0.048098884522914886, -0.04581601917743683, -0.032027002424001694, -0.14751727879047394]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.026473507285118103, 0.057878077030181885, 0.043346475809812546, 0.0964832454919815, 0.10826870799064636, -0.2157643735408783, 0.11005999147891998, -0.07113035768270493, -0.06591018289327621, -0.1922473907470703]\n",
      "input.shape=  torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q3/rbp1fpy10c3ff9w1fyr_djbr0000gn/T/ipykernel_78674/3076565514.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input[0].tolist() =  [0.0264473557472229, 0.1235949844121933, 0.01908857747912407, 0.11781458556652069, 0.13928532600402832, -0.21226471662521362, 0.12477122992277145, -0.07008680701255798, -0.11235170066356659, -0.056389059871435165]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.022085808217525482, 0.11919800937175751, 0.06294573843479156, 0.05019495263695717, 0.11905253678560257, -0.3045305907726288, 0.14603279531002045, -0.025806497782468796, -0.09955482184886932, -0.16598260402679443]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.05153945833444595, 0.04149743169546127, -0.013909861445426941, 0.15060803294181824, 0.11348707973957062, -0.26313865184783936, 0.20003986358642578, -0.0861174613237381, -0.11307249218225479, -0.12420384585857391]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.001926124095916748, 0.04949795454740524, 0.06515195965766907, 0.12909717857837677, 0.03952474147081375, -0.14906737208366394, 0.1368880271911621, -0.06298936158418655, -0.05824608355760574, -0.08977214992046356]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.13711565732955933, 0.08079791814088821, 0.03442735970020294, 0.14392942190170288, 0.2003527283668518, -0.4811960756778717, 0.4560617208480835, -0.14201873540878296, -0.14933376014232635, -0.2580035328865051]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.15389792621135712, 0.024742789566516876, 0.01625448279082775, 0.14459839463233948, 0.17984601855278015, -0.44841116666793823, 0.42528843879699707, -0.15339520573616028, -0.15395206212997437, -0.24952255189418793]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.028222251683473587, 0.08438378572463989, 0.07080228626728058, 0.029407616704702377, 0.08931483328342438, -0.33355414867401123, 0.06684560328722, -0.053732022643089294, -0.0846572071313858, -0.19006669521331787]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.09321700781583786, 0.07324235141277313, 0.004723496735095978, 0.0851193517446518, 0.18450674414634705, -0.3753519654273987, 0.3492501676082611, -0.15888001024723053, -0.11830523610115051, -0.23747846484184265]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.06950603425502777, 0.049662865698337555, 0.07284323871135712, 0.1042465791106224, 0.1587657630443573, -0.3490142822265625, 0.27186447381973267, -0.14104560017585754, -0.13169482350349426, -0.14348962903022766]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.012081712484359741, 0.0603414811193943, 0.06502147763967514, 0.0924348384141922, 0.0942009761929512, -0.1929410696029663, 0.13316909968852997, -0.09706692397594452, -0.1611994206905365, -0.04047643393278122]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.02693594992160797, 0.08412674814462662, 0.07152723520994186, 0.06868673115968704, 0.09330330044031143, -0.18249455094337463, 0.1420108526945114, -0.12576356530189514, -0.11665012687444687, -0.08620961010456085]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.07839357107877731, 0.08636480569839478, 0.13137194514274597, 0.11990311741828918, 0.1915990263223648, -0.2762402594089508, 0.2808827757835388, -0.19487303495407104, -0.21364548802375793, -0.11596205830574036]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.09869971871376038, 0.11492407321929932, -0.04158984124660492, -0.03197699040174484, 0.18868254125118256, -0.40843409299850464, 0.299238920211792, -0.21903865039348602, -0.15094493329524994, -0.338392049074173]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.10447420924901962, 0.02063785493373871, 0.1002846509218216, 0.015468653291463852, 0.2679470479488373, -0.28977805376052856, 0.32843366265296936, -0.20750099420547485, -0.20289510488510132, -0.15010815858840942]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.03696265071630478, 0.07729972153902054, 0.08418016135692596, 0.06706516444683075, 0.16824768483638763, -0.2905934751033783, 0.19922871887683868, -0.17246776819229126, -0.17087237536907196, -0.13304388523101807]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.004955194890499115, 0.08136306703090668, 0.04171730577945709, 0.04111059755086899, 0.057193707674741745, -0.12072420120239258, 0.08374740183353424, -0.0824839249253273, -0.0806807354092598, -0.08627741783857346]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.016765393316745758, 0.057415757328271866, 0.06317897140979767, 0.03516806662082672, 0.18832969665527344, -0.15760985016822815, 0.2160058319568634, -0.14757737517356873, -0.14189545810222626, -0.1311642974615097]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.014759697020053864, 0.08868218958377838, 0.02127411775290966, 0.042883746325969696, 0.1161080077290535, -0.2434881627559662, 0.15115077793598175, -0.09259958565235138, -0.07000310719013214, -0.14576247334480286]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.005783110857009888, 0.0898558497428894, 0.009202847257256508, -0.045001283288002014, 0.1410377472639084, -0.22609788179397583, 0.1405756175518036, -0.09073778986930847, -0.07402630150318146, -0.23441369831562042]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.03859198838472366, 0.1232161745429039, 0.04510766267776489, 0.011892866343259811, 0.1577254980802536, -0.2565455138683319, 0.19396258890628815, -0.13054293394088745, -0.11204198002815247, -0.23137828707695007]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.014562748372554779, 0.10037721693515778, 0.008180148899555206, -0.020708486437797546, 0.0853591188788414, -0.18599143624305725, 0.0816674456000328, -0.08112585544586182, -0.07308755069971085, -0.2127324342727661]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.03766660392284393, 0.08537443727254868, 0.020263100042939186, 0.006359944120049477, 0.13710948824882507, -0.19421759247779846, 0.1568889319896698, -0.09807655960321426, -0.10199259221553802, -0.17493900656700134]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.01624547690153122, 0.08916623890399933, 0.006599770858883858, 0.024530330672860146, 0.12131740897893906, -0.1794646978378296, 0.10701372474431992, -0.09294743835926056, -0.06804163753986359, -0.14425742626190186]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.033490777015686035, 0.1321580857038498, 0.014849107712507248, -0.057344701141119, 0.14070497453212738, -0.25107160210609436, 0.1503460556268692, -0.10375337302684784, -0.07126975059509277, -0.2791972756385803]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.09095077216625214, 0.1038433164358139, 0.007439509034156799, -0.057888470590114594, 0.24523019790649414, -0.290638267993927, 0.26047417521476746, -0.11173510551452637, -0.11404581367969513, -0.30169644951820374]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.033272236585617065, 0.1431584656238556, 0.019214970991015434, -0.01117030531167984, 0.09991364181041718, -0.17868545651435852, 0.0683421790599823, -0.048563152551651, -0.02221641130745411, -0.2308993637561798]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.00015387684106826782, 0.08683977276086807, 0.051526010036468506, -0.0007867217063903809, 0.11199671775102615, -0.19191449880599976, 0.04025162011384964, -0.09651806950569153, -0.0692739263176918, -0.16173729300498962]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.003166280686855316, 0.0823695957660675, 0.019944440573453903, -0.006033901125192642, 0.09002669155597687, -0.22309893369674683, 0.048667725175619125, -0.06753185391426086, -0.04106443375349045, -0.1984616219997406]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.0029565170407295227, 0.12245739996433258, -0.006107859313488007, 0.0208548866212368, 0.09975948929786682, -0.18790650367736816, 0.12964674830436707, -0.06921516358852386, -0.054938096553087234, -0.19272451102733612]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.03253057599067688, 0.13560503721237183, 0.05611559376120567, -0.05210225656628609, 0.16223827004432678, -0.15474173426628113, 0.08674303442239761, -0.019156286492943764, -0.06721167266368866, -0.21956227719783783]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.0030580908060073853, 0.10804979503154755, 0.028646225109696388, 0.051866378635168076, 0.1275552362203598, -0.1525021195411682, 0.11736135929822922, -0.10009624809026718, -0.11056162416934967, -0.12449488788843155]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.06113966554403305, 0.09658670425415039, -0.0038803499191999435, -0.00044937804341316223, 0.07956916093826294, -0.13911297917366028, 0.006593243218958378, -0.013764193281531334, -0.0017116926610469818, -0.15841540694236755]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.05431747063994408, 0.11734271794557571, 0.028796080499887466, 0.010099291801452637, 0.0667046308517456, -0.11426430940628052, 0.024003349244594574, -0.04064460098743439, -0.050136588513851166, -0.17961224913597107]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.036787647753953934, 0.07727576047182083, -0.010428007692098618, 0.018419578671455383, 0.09085880219936371, -0.13724389672279358, 0.029489759355783463, -0.06516818702220917, -0.07051537930965424, -0.10278291255235672]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.04082754626870155, 0.1204095184803009, -0.045814525336027145, -0.02919415757060051, 0.12975235283374786, -0.16508696973323822, 0.11719878017902374, -0.05658711493015289, -0.04547567293047905, -0.27552086114883423]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.026325121521949768, 0.08575901389122009, -0.07801280170679092, -0.00017729401588439941, 0.15703526139259338, -0.1835254430770874, 0.14020748436450958, -0.05813612416386604, -0.03477916866540909, -0.3105887174606323]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.009581923484802246, 0.130469411611557, -0.010930880904197693, -0.022023923695087433, 0.15174616873264313, -0.16561415791511536, 0.13172581791877747, -0.06620272248983383, -0.10679645836353302, -0.17729264497756958]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.010453931987285614, 0.1303168386220932, 0.013412141241133213, 0.060467805713415146, 0.07486164569854736, -0.10999328643083572, 0.07338167726993561, -0.08467034995555878, -0.0809926763176918, -0.12628281116485596]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.007180556654930115, 0.07206489145755768, -0.07771290838718414, -0.01964777335524559, 0.16337493062019348, -0.1704147756099701, 0.16928181052207947, -0.09622125327587128, -0.06493666768074036, -0.2774372696876526]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.026629801839590073, 0.07524950057268143, -0.03362720459699631, -0.03087986260652542, 0.12128114700317383, -0.08694985508918762, 0.08534304052591324, -0.04396996647119522, -0.04028408229351044, -0.22908279299736023]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [-0.021211698651313782, 0.06587660312652588, -0.05864735692739487, -0.11779673397541046, 0.14830908179283142, -0.1966579258441925, 0.1440213918685913, -0.08390301465988159, -0.07636985927820206, -0.27933764457702637]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.016381017863750458, 0.11602365225553513, -0.07423736900091171, -0.07030196487903595, 0.12536735832691193, -0.20123538374900818, 0.13657408952713013, -0.08205713331699371, -0.05016804113984108, -0.2898316979408264]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.0571284256875515, 0.07734227180480957, -0.05662258341908455, -0.042217377573251724, 0.08975926041603088, -0.10321760177612305, 0.06699202209711075, -0.06350366771221161, 0.001988448202610016, -0.2780672609806061]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.05099687725305557, 0.07578377425670624, -0.08740971982479095, -0.05745803564786911, 0.10657267272472382, -0.15651275217533112, 0.11671017110347748, -0.07965646684169769, 5.5324286222457886e-05, -0.33229702711105347]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.014575488865375519, 0.10677792876958847, -0.03545820713043213, 0.01527349092066288, 0.12257272005081177, -0.15439677238464355, 0.12924699485301971, -0.07662305235862732, -0.10797721147537231, -0.13887840509414673]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.017392665147781372, 0.057880427688360214, -0.10877838730812073, -0.0335664264857769, 0.10029609501361847, -0.17120075225830078, 0.10797938704490662, -0.09241607785224915, -0.03663912042975426, -0.274929404258728]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.07721129059791565, 0.06002315506339073, -0.07292868942022324, 0.03699669986963272, 0.09914146363735199, -0.09632257372140884, 0.10499779134988785, -0.1083277016878128, -0.008311349898576736, -0.17360524833202362]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.11589144170284271, 0.03639855235815048, -0.08343803882598877, -0.03274025395512581, 0.0964534729719162, -0.03382505476474762, 0.04603468254208565, -0.02871542051434517, 0.05679312348365784, -0.26885154843330383]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.0854596495628357, 0.048353567719459534, -0.0939183384180069, -0.049096979200839996, 0.05617213994264603, -0.06021495908498764, 0.03912344574928284, -0.0718303918838501, 0.02966560423374176, -0.2864849269390106]\n",
      "input.shape=  torch.Size([1, 10])\n",
      "input[0].tolist() =  [0.05012071505188942, 0.07997369021177292, -0.012136762030422688, 0.044798918068408966, 0.08065380156040192, -0.10878200829029083, 0.06729196012020111, -0.07568135857582092, -0.0536370649933815, -0.12566374242305756]\n",
      "input.shape=  torch.Size([1, 10])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(output, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Optimize the weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/torch/autograd/function.py:267\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mImplementing both \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbackward\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mvjp\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for a custom \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mFunction is not allowed. You should only implement one \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mof them.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    266\u001b[0m user_fn \u001b[39m=\u001b[39m vjp_fn \u001b[39mif\u001b[39;00m vjp_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Function\u001b[39m.\u001b[39mvjp \u001b[39melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 267\u001b[0m \u001b[39mreturn\u001b[39;00m user_fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "\u001b[1;32m/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb Cell 20\u001b[0m in \u001b[0;36mHybridFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(input_list)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     expectation_right \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mquantum_circuit\u001b[39m.\u001b[39mrun(shift_right[i])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     expectation_left  \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39;49mquantum_circuit\u001b[39m.\u001b[39;49mrun(shift_left[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     gradient \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (torch\u001b[39m.\u001b[39mtensor([expectation_right]) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mtensor([expectation_left]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m#print('gradient = ', gradient)\u001b[39;00m\n",
      "\u001b[1;32m/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb Cell 20\u001b[0m in \u001b[0;36mQuantumCircuit.run\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     dict_for_use[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta[i]] \u001b[39m=\u001b[39m thetas[i]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m qobj \u001b[39m=\u001b[39m assemble(t_qc,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                 shots\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshots,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                 parameter_binds \u001b[39m=\u001b[39;49m [dict_for_use])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mrun(qobj)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jerry1203/Desktop/CommLab_2022Final/multi-classifier_10_qubit_output_layer.ipynb#X31sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m result \u001b[39m=\u001b[39m job\u001b[39m.\u001b[39mresult()\u001b[39m.\u001b[39mget_counts()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/qiskit/compiler/assembler.py:203\u001b[0m, in \u001b[0;36massemble\u001b[0;34m(experiments, backend, qobj_id, qobj_header, shots, memory, max_credits, seed_simulator, qubit_lo_freq, meas_lo_freq, qubit_lo_range, meas_lo_range, schedule_los, meas_level, meas_return, meas_map, memory_slot_size, rep_time, rep_delay, parameter_binds, parametric_pulses, init_qubits, **run_config)\u001b[0m\n\u001b[1;32m    193\u001b[0m run_config \u001b[39m=\u001b[39m _parse_circuit_args(\n\u001b[1;32m    194\u001b[0m     parameter_binds,\n\u001b[1;32m    195\u001b[0m     backend,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrun_config_common_dict,\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    202\u001b[0m \u001b[39m# If circuits are parameterized, bind parameters and remove from run_config\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m bound_experiments, run_config \u001b[39m=\u001b[39m _expand_parameters(\n\u001b[1;32m    204\u001b[0m     circuits\u001b[39m=\u001b[39;49mexperiments, run_config\u001b[39m=\u001b[39;49mrun_config\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    206\u001b[0m end_time \u001b[39m=\u001b[39m time()\n\u001b[1;32m    207\u001b[0m _log_assembly_time(start_time, end_time)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/qiskit/compiler/assembler.py:580\u001b[0m, in \u001b[0;36m_expand_parameters\u001b[0;34m(circuits, run_config)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m parameter_binds \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(parameter_binds) \u001b[39mor\u001b[39;00m \u001b[39many\u001b[39m(circuit\u001b[39m.\u001b[39mparameters \u001b[39mfor\u001b[39;00m circuit \u001b[39min\u001b[39;00m circuits):\n\u001b[1;32m    574\u001b[0m \n\u001b[1;32m    575\u001b[0m     \u001b[39m# Unroll params here in order to handle ParamVects\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     all_bind_parameters \u001b[39m=\u001b[39m [\n\u001b[1;32m    577\u001b[0m         QuantumCircuit()\u001b[39m.\u001b[39m_unroll_param_dict(bind)\u001b[39m.\u001b[39mkeys() \u001b[39mfor\u001b[39;00m bind \u001b[39min\u001b[39;00m parameter_binds\n\u001b[1;32m    578\u001b[0m     ]\n\u001b[0;32m--> 580\u001b[0m     all_circuit_parameters \u001b[39m=\u001b[39m [circuit\u001b[39m.\u001b[39mparameters \u001b[39mfor\u001b[39;00m circuit \u001b[39min\u001b[39;00m circuits]\n\u001b[1;32m    582\u001b[0m     \u001b[39m# Collect set of all unique parameters across all circuits and binds\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     unique_parameters \u001b[39m=\u001b[39m {\n\u001b[1;32m    584\u001b[0m         param\n\u001b[1;32m    585\u001b[0m         \u001b[39mfor\u001b[39;00m param_list \u001b[39min\u001b[39;00m all_bind_parameters \u001b[39m+\u001b[39m all_circuit_parameters\n\u001b[1;32m    586\u001b[0m         \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m param_list\n\u001b[1;32m    587\u001b[0m     }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/qiskit/compiler/assembler.py:580\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m parameter_binds \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(parameter_binds) \u001b[39mor\u001b[39;00m \u001b[39many\u001b[39m(circuit\u001b[39m.\u001b[39mparameters \u001b[39mfor\u001b[39;00m circuit \u001b[39min\u001b[39;00m circuits):\n\u001b[1;32m    574\u001b[0m \n\u001b[1;32m    575\u001b[0m     \u001b[39m# Unroll params here in order to handle ParamVects\u001b[39;00m\n\u001b[1;32m    576\u001b[0m     all_bind_parameters \u001b[39m=\u001b[39m [\n\u001b[1;32m    577\u001b[0m         QuantumCircuit()\u001b[39m.\u001b[39m_unroll_param_dict(bind)\u001b[39m.\u001b[39mkeys() \u001b[39mfor\u001b[39;00m bind \u001b[39min\u001b[39;00m parameter_binds\n\u001b[1;32m    578\u001b[0m     ]\n\u001b[0;32m--> 580\u001b[0m     all_circuit_parameters \u001b[39m=\u001b[39m [circuit\u001b[39m.\u001b[39;49mparameters \u001b[39mfor\u001b[39;00m circuit \u001b[39min\u001b[39;00m circuits]\n\u001b[1;32m    582\u001b[0m     \u001b[39m# Collect set of all unique parameters across all circuits and binds\u001b[39;00m\n\u001b[1;32m    583\u001b[0m     unique_parameters \u001b[39m=\u001b[39m {\n\u001b[1;32m    584\u001b[0m         param\n\u001b[1;32m    585\u001b[0m         \u001b[39mfor\u001b[39;00m param_list \u001b[39min\u001b[39;00m all_bind_parameters \u001b[39m+\u001b[39m all_circuit_parameters\n\u001b[1;32m    586\u001b[0m         \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m param_list\n\u001b[1;32m    587\u001b[0m     }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/qiskit/circuit/quantumcircuit.py:2585\u001b[0m, in \u001b[0;36mQuantumCircuit.parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m \u001b[39m# parameters from gates\u001b[39;00m\n\u001b[1;32m   2584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameters \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2585\u001b[0m     unsorted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_unsorted_parameters()\n\u001b[1;32m   2586\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parameters \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(unsorted, key\u001b[39m=\u001b[39mfunctools\u001b[39m.\u001b[39mcmp_to_key(_compare_parameters))\n\u001b[1;32m   2588\u001b[0m \u001b[39m# return as parameter view, which implements the set and list interface\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/qiskit/circuit/quantumcircuit.py:2598\u001b[0m, in \u001b[0;36mQuantumCircuit._unsorted_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2596\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unsorted_parameters\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Set[Parameter]:\n\u001b[1;32m   2597\u001b[0m     \u001b[39m\"\"\"Efficiently get all parameters in the circuit, without any sorting overhead.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2598\u001b[0m     parameters \u001b[39m=\u001b[39m \u001b[39mset\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_table)\n\u001b[1;32m   2599\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_phase, ParameterExpression):\n\u001b[1;32m   2600\u001b[0m         parameters\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_phase\u001b[39m.\u001b[39mparameters)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IBMQ/lib/python3.10/site-packages/qiskit/circuit/parameter.py:117\u001b[0m, in \u001b[0;36mParameter.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__hash__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hash\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getstate__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.NLLLoss()\n",
    "#loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #print(target == 7)\n",
    "        #print(target.numpy()[0] == 7)\n",
    "        '''\n",
    "        if target.numpy()[0] == 7:\n",
    "            target = torch.LongTensor([0])\n",
    "            '''\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        #print(data.size())\n",
    "        output = model(data)\n",
    "        # Calculating loss\n",
    "        #print('output = ', output)\n",
    "        #print('target = ', target)\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Neg Log Likelihood Loss')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Concentrating on the first 100 samples\n",
    "n_samples = 50\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
    "                np.where(X_test.targets == 1)[0][:n_samples])\n",
    "\n",
    "for i in range(2, 10):\n",
    "    idx = np.append(idx, np.where(X_test.targets == i)[0][:n_samples])\n",
    "    \n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "#print(X_test.targets)\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on test data:\n",
      "\tLoss: -0.2135\n",
      "\tAccuracy: 94.4%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        #print('pred')\n",
    "        #print(pred)\n",
    "        #print('target')\n",
    "        #print(target)\n",
    "        #print(pred.eq(target.view_as(pred)).sum().item())\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        #print(output, target)\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "        sum(total_loss) / len(total_loss),\n",
    "        correct / len(test_loader) * 100)\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('IBMQ')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d4840b60a59fe0c35ad7703cffab0f5101171e21a03959fba8163ad7bec285c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
